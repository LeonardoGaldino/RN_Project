{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, BorderlineSMOTE, ADASYN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "ds = pd.read_csv('TRN', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "\n",
    "features = ds.columns.drop(['INDEX', 'IND_BOM_1_1', 'IND_BOM_1_2'])\n",
    "X = ds[features]\n",
    "y = ds['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for train, validation and test\n",
    "# Train: 1/2\n",
    "# Validation: 1/4\n",
    "# Test: 1/4\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, stratify=y, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.98, stratify=y_train, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [0, 1, 2, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]\n",
    "sm = BorderlineSMOTE(random_state=123, sampling_strategy='minority')\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3826, 0: 3826})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for testing models\n",
    "\n",
    "# Accuracy: (TP + TN) / N\n",
    "# Precision: TP / (TP + FP)\n",
    "# Recall: TP / (TP + FN)\n",
    "# F1-Measure: Harmonic average between Precision and Recall\n",
    "\n",
    "def compute_metrics(pred, pred_probs, y, neg_class=0):\n",
    "    cm = confusion_matrix(y_true=y, y_pred=pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "    f_measure = f1_score(y, pred)\n",
    "    \n",
    "    pred_probs = np.array([v[0] if v[0] > v[1] else v[1] for v in pred_probs])\n",
    "    roc_auc = roc_auc_score(y, pred_probs)\n",
    "    pr_auc = average_precision_score(y, pred_probs)\n",
    "    gd = generate_dist(pred_probs, np.array(y), neg_class)\n",
    "    ks = ks_2samp(gd[0], gd[1])[0]\n",
    "    return acc, precision, recall, f_measure, roc_auc, pr_auc, ks, cm\n",
    "\n",
    "def report_performance_metrics(pred, pred_probs, _y, neg_class=0):\n",
    "    acc, prec, rec, f_measure, roc_auc, pr_auc, ks, cm = compute_metrics(pred, pred_probs, _y, neg_class)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', rec)\n",
    "    print('F-Measure:', f_measure)\n",
    "    print('AUROC:', roc_auc)\n",
    "    print('AUPR:', pr_auc)\n",
    "    print('Confusion Matrix:')\n",
    "    print('KS test:', ks)\n",
    "    print(cm)\n",
    "    \n",
    "def train_test_k_fold(k, clf, _X, _y, neg_class=0):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "    it = 1\n",
    "    for train_index, test_index in skf.split(_X, _y):\n",
    "        X_batch = _X[train_index]\n",
    "        y_batch = _y[train_index]\n",
    "        X_test_batch = _X[test_index]\n",
    "        y_test_batch = _y[test_index]\n",
    "        clf.fit(X_batch, y_batch)\n",
    "        results = clf.predict(X_test_batch)\n",
    "        results_probs = clf.predict_proba(X_test_batch)\n",
    "        print('K Fold it', it)\n",
    "        report_performance_metrics(results, results_probs, y_test_batch, neg_class)\n",
    "        print('')\n",
    "        it += 1\n",
    "        \n",
    "def test_model(clf, _X, _y):\n",
    "    results = clf.predict(_X)\n",
    "    results_probs = clf.predict_proba(_X)\n",
    "    report_performance_metrics(results, results_probs, _y)\n",
    "    \n",
    "def generate_dist(probas, y, neg_class):\n",
    "    dist_1 = [0] * 100\n",
    "    dist_2 = [0] * 100\n",
    "    for_perc = Counter(y)\n",
    "    for i in range(1,101):\n",
    "        limiar = i/100        \n",
    "        lower = y[np.where(probas <= limiar)]\n",
    "        count = Counter(lower)\n",
    "        dist_1[i-1] = count[neg_class]\n",
    "        dist_2[i-1] = count[1]\n",
    "    return np.array(dist_1)/for_perc[neg_class], np.array(dist_2)/for_perc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_X_train = np.delete(X_train, cat_cols, 1)\n",
    "#kk = np.delete(X_val, cat_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"params = {\\n    'kernel': ['rbf', 'linear', 'poly'],\\n    'C': [.0001, .01, 1, 10, 100],\\n    'gamma': [.0001, .001, .01, .1, 1, 10, 100],\\n}\\n\\nclf = svm.SVC(decision_function_shape='ovo', verbose=True, max_iter=500)\\ngrid = GridSearchCV(estimator=clf, param_grid=params)\\nsearch = grid.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''params = {\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'C': [.0001, .01, 1, 10, 100],\n",
    "    'gamma': [.0001, .001, .01, .1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', verbose=True, max_iter=500)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=params)\n",
    "search = grid.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = search.best_params_\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold it 1\n",
      "Accuracy: 0.610313315926893\n",
      "Precision: 0.651705565529623\n",
      "Recall: 0.47389033942558745\n",
      "F-Measure: 0.5487528344671202\n",
      "AUROC: 0.3712650573662647\n",
      "AUPR: 0.4039976017926113\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[572 194]\n",
      " [403 363]]\n",
      "\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold it 2\n",
      "Accuracy: 0.6457516339869281\n",
      "Precision: 0.6335329341317365\n",
      "Recall: 0.6915032679738562\n",
      "F-Measure: 0.66125\n",
      "AUROC: 0.4256038275876799\n",
      "AUPR: 0.42962050999648754\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[459 306]\n",
      " [236 529]]\n",
      "\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold it 3\n",
      "Accuracy: 0.5516339869281046\n",
      "Precision: 0.7231638418079096\n",
      "Recall: 0.16732026143790849\n",
      "F-Measure: 0.27176220806794055\n",
      "AUROC: 0.3330334486735871\n",
      "AUPR: 0.3906227056666516\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[716  49]\n",
      " [637 128]]\n",
      "\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold it 4\n",
      "Accuracy: 0.6620915032679738\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6483660130718955\n",
      "F-Measure: 0.6573889993373094\n",
      "AUROC: 0.4191874919902602\n",
      "AUPR: 0.43052437678679584\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[517 248]\n",
      " [269 496]]\n",
      "\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold it 5\n",
      "Accuracy: 0.6169934640522876\n",
      "Precision: 0.6765285996055227\n",
      "Recall: 0.44836601307189544\n",
      "F-Measure: 0.5393081761006289\n",
      "AUROC: 0.3415916955017301\n",
      "AUPR: 0.39418064337313363\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[601 164]\n",
      " [422 343]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Train SVM with k fold \n",
    "\n",
    "params = {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "svm_clf = svm.SVC(**params, decision_function_shape='ovo', \n",
    "              verbose=True, max_iter=200, probability=True)\n",
    "\n",
    "_y_train = np.array([v if v == 1 else -1 for v in y_train])\n",
    "\n",
    "train_test_k_fold(5, svm_clf, X_train, _y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5114441052837131\n",
      "Precision: 0.694943334613907\n",
      "Recall: 0.45383698685984886\n",
      "F-Measure: 0.549088425565821\n",
      "AUROC: 0.47351870478870123\n",
      "AUPR: 0.6423656144249102\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[20820 12705]\n",
      " [34831 28943]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Test SVM  on validation set\n",
    "\n",
    "_y_val = np.array([v if v == 1 else -1 for v in y_val])\n",
    "test_model(svm_clf, X_val, _y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5086205691113752\n",
      "Precision: 0.6928995347460831\n",
      "Recall: 0.4495727954431514\n",
      "F-Measure: 0.5453239830245316\n",
      "AUROC: 0.4771637838211466\n",
      "AUPR: 0.645337652422363\n",
      "Confusion Matrix:\n",
      "KS test: 1.0\n",
      "[[ 61202  37360]\n",
      " [103204  84294]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Test SVM on test set\n",
    "\n",
    "_y_test = np.array([v if v == 1 else -1 for v in y_test])\n",
    "test_model(svm_clf, X_test, _y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                               batch_size=128, beta_1=0.9,\n",
       "                                               beta_2=0.999,\n",
       "                                               early_stopping=False,\n",
       "                                               epsilon=1e-08,\n",
       "                                               hidden_layer_sizes=(12, 12),\n",
       "                                               learning_rate='constant',\n",
       "                                               learning_rate_init=0.005,\n",
       "                                               max_iter=20, momentum=0.9,\n",
       "                                               n_iter_no_change=10,\n",
       "                                               nesterovs_momentum=True,\n",
       "                                               power_t=0.5, random_state=None,\n",
       "                                               shuffle=True, solver='adam',\n",
       "                                               tol=1e-07,\n",
       "                                               validation_fraction=0.1,\n",
       "                                               verbose=True, warm_start=False),\n",
       "                  bootstrap=False, bootstrap_features=True, max_features=1.0,\n",
       "                  max_samples=0.2, n_estimators=5, n_jobs=8, oob_score=False,\n",
       "                  random_state=None, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define MLP ensemble (Bagging method) and train it\n",
    "\n",
    "_mlp = MLPClassifier(hidden_layer_sizes= (12, 12), learning_rate_init= 0.005, solver= 'adam',\n",
    "                     alpha=1e-4, verbose=True, activation='relu', batch_size=128, max_iter=20, tol=1e-7)\n",
    "\n",
    "mlp_ensemble = BaggingClassifier(base_estimator=_mlp, n_estimators=5, max_samples=.2, \n",
    "                  bootstrap=False, bootstrap_features=True, n_jobs=8, verbose=True)\n",
    "\n",
    "mlp_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5938601630027031\n",
      "Precision: 0.7395753086419753\n",
      "Recall: 0.5870887822623639\n",
      "F-Measure: 0.6545686588169477\n",
      "AUROC: 0.5192103998770641\n",
      "AUPR: 0.6827023913882746\n",
      "Confusion Matrix:\n",
      "KS test: 0.03\n",
      "[[20341 13184]\n",
      " [26333 37441]]\n"
     ]
    }
   ],
   "source": [
    "# Test MLP ensemble on validation set\n",
    "\n",
    "test_model(mlp_ensemble, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5957980843179752\n",
      "Precision: 0.7408901997586808\n",
      "Recall: 0.5894782877684028\n",
      "F-Measure: 0.6565679967209024\n",
      "AUROC: 0.5200043160558591\n",
      "AUPR: 0.6824004773096084\n",
      "Confusion Matrix:\n",
      "KS test: 0.04\n",
      "[[ 59908  38654]\n",
      " [ 76972 110526]]\n"
     ]
    }
   ],
   "source": [
    "# Test MLP Ensemble on test set \n",
    "\n",
    "test_model(mlp_ensemble, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"solvers = ['lbfgs', 'adam',]\\nhidden_layers = [(12,12), (12,12,12), (5,5,5), (5,5)]\\nlearning_rates = [.001, .0001, .005]\\n\\nclf = MLPClassifier()\\ngrid = GridSearchCV(estimator=clf, param_grid=dict(solver=solvers, hidden_layer_sizes=hidden_layers, learning_rate_init=learning_rates))\\nsearch = grid.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run grid search to find best parameters\n",
    "'''\n",
    "    Best parameters found:\n",
    "        Solver: adam\n",
    "        hidden_layers: (12,12)\n",
    "        learning_rate: 0.005\n",
    "'''\n",
    "\n",
    "\n",
    "'''solvers = ['lbfgs', 'adam',]\n",
    "hidden_layers = [(12,12), (12,12,12), (5,5,5), (5,5)]\n",
    "learning_rates = [.001, .0001, .005]\n",
    "\n",
    "clf = MLPClassifier()\n",
    "grid = GridSearchCV(estimator=clf, param_grid=dict(solver=solvers, hidden_layer_sizes=hidden_layers, learning_rate_init=learning_rates))\n",
    "search = grid.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename best parameters found on grid search\n",
    "\n",
    "#params = search.best_params_\n",
    "\n",
    "params = {\n",
    "    'solver': 'adam',\n",
    "    'hidden_layer_sizes': (12,12),\n",
    "    'learning_rate_init': .005,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68333623\n",
      "Iteration 2, loss = 0.65684013\n",
      "Iteration 3, loss = 0.63781253\n",
      "Iteration 4, loss = 0.62808814\n",
      "Iteration 5, loss = 0.62358680\n",
      "Iteration 6, loss = 0.61743380\n",
      "Iteration 7, loss = 0.61664109\n",
      "Iteration 8, loss = 0.60945337\n",
      "Iteration 9, loss = 0.60079372\n",
      "Iteration 10, loss = 0.60183473\n",
      "Iteration 11, loss = 0.60025061\n",
      "Iteration 12, loss = 0.59713203\n",
      "Iteration 13, loss = 0.59237457\n",
      "Iteration 14, loss = 0.58755480\n",
      "Iteration 15, loss = 0.58239075\n",
      "Iteration 16, loss = 0.58453338\n",
      "Iteration 17, loss = 0.58424987\n",
      "Iteration 18, loss = 0.58069505\n",
      "Iteration 19, loss = 0.58949189\n",
      "Iteration 20, loss = 0.57302026\n",
      "K Fold it 1\n",
      "Accuracy: 0.6422976501305483\n",
      "Precision: 0.653954802259887\n",
      "Recall: 0.6044386422976501\n",
      "F-Measure: 0.6282225237449117\n",
      "AUROC: 0.6138582306785103\n",
      "AUPR: 0.6508822355874017\n",
      "Confusion Matrix:\n",
      "KS test: 0.19\n",
      "[[521 245]\n",
      " [303 463]]\n",
      "\n",
      "Iteration 1, loss = 0.70555977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.65876761\n",
      "Iteration 3, loss = 0.64085972\n",
      "Iteration 4, loss = 0.63303489\n",
      "Iteration 5, loss = 0.62313058\n",
      "Iteration 6, loss = 0.61829124\n",
      "Iteration 7, loss = 0.61236887\n",
      "Iteration 8, loss = 0.60404994\n",
      "Iteration 9, loss = 0.60563324\n",
      "Iteration 10, loss = 0.59751181\n",
      "Iteration 11, loss = 0.59640858\n",
      "Iteration 12, loss = 0.59215258\n",
      "Iteration 13, loss = 0.58745750\n",
      "Iteration 14, loss = 0.58444033\n",
      "Iteration 15, loss = 0.58302784\n",
      "Iteration 16, loss = 0.58091100\n",
      "Iteration 17, loss = 0.58396349\n",
      "Iteration 18, loss = 0.57448652\n",
      "Iteration 19, loss = 0.57164912\n",
      "Iteration 20, loss = 0.56570873\n",
      "K Fold it 2\n",
      "Accuracy: 0.6274509803921569\n",
      "Precision: 0.66553480475382\n",
      "Recall: 0.5124183006535947\n",
      "F-Measure: 0.5790251107828656\n",
      "AUROC: 0.5031944978427101\n",
      "AUPR: 0.5501695909820914\n",
      "Confusion Matrix:\n",
      "KS test: 0.06\n",
      "[[568 197]\n",
      " [373 392]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68248533\n",
      "Iteration 2, loss = 0.65314712\n",
      "Iteration 3, loss = 0.63687531\n",
      "Iteration 4, loss = 0.62643553\n",
      "Iteration 5, loss = 0.61177484\n",
      "Iteration 6, loss = 0.60316173\n",
      "Iteration 7, loss = 0.60026143\n",
      "Iteration 8, loss = 0.58753599\n",
      "Iteration 9, loss = 0.58055257\n",
      "Iteration 10, loss = 0.57436161\n",
      "Iteration 11, loss = 0.56287586\n",
      "Iteration 12, loss = 0.55778484\n",
      "Iteration 13, loss = 0.54643348\n",
      "Iteration 14, loss = 0.54765290\n",
      "Iteration 15, loss = 0.54016007\n",
      "Iteration 16, loss = 0.53130574\n",
      "Iteration 17, loss = 0.52117662\n",
      "Iteration 18, loss = 0.51576892\n",
      "Iteration 19, loss = 0.50276344\n",
      "Iteration 20, loss = 0.49470109\n",
      "K Fold it 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6503267973856209\n",
      "Precision: 0.650523560209424\n",
      "Recall: 0.6496732026143791\n",
      "F-Measure: 0.6500981033355133\n",
      "AUROC: 0.6027784185569652\n",
      "AUPR: 0.6407847866322154\n",
      "Confusion Matrix:\n",
      "KS test: 0.09\n",
      "[[498 267]\n",
      " [268 497]]\n",
      "\n",
      "Iteration 1, loss = 0.68249701\n",
      "Iteration 2, loss = 0.65883465\n",
      "Iteration 3, loss = 0.64403681\n",
      "Iteration 4, loss = 0.63128869\n",
      "Iteration 5, loss = 0.62711376\n",
      "Iteration 6, loss = 0.61415526\n",
      "Iteration 7, loss = 0.60776817\n",
      "Iteration 8, loss = 0.59599049\n",
      "Iteration 9, loss = 0.59318326\n",
      "Iteration 10, loss = 0.57633810\n",
      "Iteration 11, loss = 0.57128107\n",
      "Iteration 12, loss = 0.56149254\n",
      "Iteration 13, loss = 0.54973356\n",
      "Iteration 14, loss = 0.55163631\n",
      "Iteration 15, loss = 0.53158102\n",
      "Iteration 16, loss = 0.52149683\n",
      "Iteration 17, loss = 0.51220162\n",
      "Iteration 18, loss = 0.51438648\n",
      "Iteration 19, loss = 0.50122906\n",
      "Iteration 20, loss = 0.48403231\n",
      "K Fold it 4\n",
      "Accuracy: 0.6529411764705882\n",
      "Precision: 0.6833855799373041\n",
      "Recall: 0.5699346405228758\n",
      "F-Measure: 0.6215253029223093\n",
      "AUROC: 0.5449339997436883\n",
      "AUPR: 0.5908304535809425\n",
      "Confusion Matrix:\n",
      "KS test: 0.09\n",
      "[[563 202]\n",
      " [329 436]]\n",
      "\n",
      "Iteration 1, loss = 0.68866928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.65313523\n",
      "Iteration 3, loss = 0.63952207\n",
      "Iteration 4, loss = 0.62345642\n",
      "Iteration 5, loss = 0.61820747\n",
      "Iteration 6, loss = 0.60470626\n",
      "Iteration 7, loss = 0.59839797\n",
      "Iteration 8, loss = 0.58676391\n",
      "Iteration 9, loss = 0.57518038\n",
      "Iteration 10, loss = 0.56361568\n",
      "Iteration 11, loss = 0.55069428\n",
      "Iteration 12, loss = 0.54585989\n",
      "Iteration 13, loss = 0.52861499\n",
      "Iteration 14, loss = 0.52369920\n",
      "Iteration 15, loss = 0.50693164\n",
      "Iteration 16, loss = 0.49709760\n",
      "Iteration 17, loss = 0.50069469\n",
      "Iteration 18, loss = 0.49766130\n",
      "Iteration 19, loss = 0.47309087\n",
      "Iteration 20, loss = 0.46658335\n",
      "K Fold it 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6627450980392157\n",
      "Precision: 0.6936236391912908\n",
      "Recall: 0.5830065359477125\n",
      "F-Measure: 0.6335227272727273\n",
      "AUROC: 0.559842795506002\n",
      "AUPR: 0.5968546291256449\n",
      "Confusion Matrix:\n",
      "KS test: 0.06\n",
      "[[568 197]\n",
      " [319 446]]\n",
      "\n",
      "Iteration 1, loss = 0.68478905\n",
      "Iteration 2, loss = 0.66010209\n",
      "Iteration 3, loss = 0.64492215\n",
      "Iteration 4, loss = 0.63423256\n",
      "Iteration 5, loss = 0.62649213\n",
      "Iteration 6, loss = 0.61770371\n",
      "Iteration 7, loss = 0.61240575\n",
      "Iteration 8, loss = 0.60578288\n",
      "Iteration 9, loss = 0.59837804\n",
      "Iteration 10, loss = 0.59003593\n",
      "Iteration 11, loss = 0.58388256\n",
      "Iteration 12, loss = 0.58263487\n",
      "Iteration 13, loss = 0.57407410\n",
      "Iteration 14, loss = 0.56429326\n",
      "Iteration 15, loss = 0.55712218\n",
      "Iteration 16, loss = 0.55766480\n",
      "Iteration 17, loss = 0.54881600\n",
      "Iteration 18, loss = 0.54444262\n",
      "Iteration 19, loss = 0.53933141\n",
      "Iteration 20, loss = 0.52956263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcgm/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size=128, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(12, 12), learning_rate='constant',\n",
       "              learning_rate_init=0.005, max_iter=20, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=1e-07,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train MLP with best parameters found on grid search\n",
    "mlp = MLPClassifier(**params, alpha=1e-4, verbose=True, activation='relu', batch_size=128, max_iter=20, tol=1e-7)\n",
    "\n",
    "# Uncomment below line to run k fold on the MLP\n",
    "train_test_k_fold(5, mlp, X_train, y_train)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"input_dims = X_train.shape\\n\\nmodel = Sequential()\\nmodel.add(Dense(1, input_dim=input_dims[1], activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\nmodel.compile(loss='mean_squared_error', optimizer='adam')\\n\\nX_train, y_train = shuffle(X_train, y_train)\\nX_val, y_val = shuffle(X_val, y_val)\\nX_val, y_val = np.array(X_val), np.array(y_val)\\n\\nhistory = model.fit(X_train, y_train, epochs=2, shuffle=True, batch_size=128, validation_data=(X_val, y_val))\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Keras MLP\n",
    "\n",
    "'''input_dims = X_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=input_dims[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_val, y_val = shuffle(X_val, y_val)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2, shuffle=True, batch_size=128, validation_data=(X_val, y_val))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.584785044039507\n",
      "Precision: 0.7147792847428971\n",
      "Recall: 0.6098723617775269\n",
      "F-Measure: 0.6581717264020035\n",
      "AUROC: 0.5483018632607544\n",
      "AUPR: 0.7121323470820173\n",
      "Confusion Matrix:\n",
      "KS test: 0.07\n",
      "[[18005 15520]\n",
      " [24880 38894]]\n"
     ]
    }
   ],
   "source": [
    "# Test MLP on validation set\n",
    "\n",
    "test_model(mlp, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5864329161714326\n",
      "Precision: 0.7165841351721893\n",
      "Recall: 0.6104865118561265\n",
      "F-Measure: 0.6592941379757226\n",
      "AUROC: 0.5482744191092763\n",
      "AUPR: 0.7121686237212258\n",
      "Confusion Matrix:\n",
      "KS test: 0.07\n",
      "[[ 53290  45272]\n",
      " [ 73033 114465]]\n"
     ]
    }
   ],
   "source": [
    "# Test MLP on test set\n",
    "\n",
    "test_model(mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
