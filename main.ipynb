{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "ds = pd.read_csv('TRN', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "\n",
    "features = ds.columns.drop(['IND_BOM_1_1', 'IND_BOM_1_2'])\n",
    "X = ds[features]\n",
    "y = ds['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for train, validation and test\n",
    "# Train: 1/2\n",
    "# Validation: 1/4\n",
    "# Test: 1/4\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, stratify=y, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.33, stratify=y_train, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebalance data (class 0 has way less samples than class 1)\n",
    "\n",
    "sm = SMOTE(random_state=45)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256372 samples, validate on 97299 samples\n",
      "Epoch 1/2\n",
      "256372/256372 [==============================] - 5s 20us/step - loss: 0.2500 - val_loss: 0.2507\n",
      "Epoch 2/2\n",
      "256372/256372 [==============================] - 3s 12us/step - loss: 0.2500 - val_loss: 0.2499\n"
     ]
    }
   ],
   "source": [
    "# Train the model (learn parameters)\n",
    "\n",
    "# clf = MLPClassifier(solver='lbfgs', alpha=1e-4, learning_rate_init=.001, hidden_layer_sizes=(8,8,8), random_state=1, activation='relu')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "input_dims = X_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=input_dims[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_val, y_val = shuffle(X_val, y_val)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2, shuffle=True, batch_size=128, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test dataset\n",
    "\n",
    "#results = clf.predict(X_val)\n",
    "#results_probs = clf.predict_proba(X_val)\n",
    "\n",
    "#loss, _ = model.evaluate(X_val, y_val, batch_size=128)\n",
    "results = model.predict_classes(X_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96323\n",
      "{'val_loss': [0.2507265499436263, 0.24994944172431294], 'loss': [0.25000850877995745, 0.25000788952049835]}\n"
     ]
    }
   ],
   "source": [
    "print(len([v for v in results if v == 1]))\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 33189 0 63138\n",
      "0.6554548568937059 0.6554548568937059 1.0 0.7918728247577839 0.4999754691878363 0.6554437770653577 [[    0 33189]\n",
      " [    0 63138]]\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "\n",
    "# Accuracy: (TP + TN) / N\n",
    "# Precision: TP / (TP + FP)\n",
    "# Recall: TP / (TP + FN)\n",
    "# F1-Measure: Harmonic average between Precision and Recall\n",
    "\n",
    "def compute_metrics(pred, pred_probs, y):\n",
    "    cm = confusion_matrix(y_true=y, y_pred=pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "    f_measure = f1_score(y, pred)\n",
    "    roc_auc = roc_auc_score(y, pred_probs[:,0])\n",
    "    pr_auc = average_precision_score(y, pred_probs[:,0])\n",
    "    print(tn, fp, fn, tp)\n",
    "    return acc, precision, recall, f_measure, roc_auc, pr_auc, cm\n",
    "\n",
    "acc, prec, rec, f_measure, roc_auc, pr_auc, cm = compute_metrics(results, results_probs, y_val)\n",
    "print(acc, prec, rec, f_measure, roc_auc, pr_auc, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for validation dataset\n",
    "\n",
    "results = clf.predict(X_test)\n",
    "results_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 33524 0 63774\n",
      "0.6554538073361494 0.6554502661925219 1.0 0.7918694745207112 0.49996156590151364 0.6554235627229548 [[    1 33524]\n",
      " [    0 63774]]\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f_measure, roc_auc, pr_auc, cm = compute_metrics(results, results_probs, y_test)\n",
    "print(acc, prec, rec, f_measure, roc_auc, pr_auc, cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
