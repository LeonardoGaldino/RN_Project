{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlsma/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import scikitplot as skplt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "ds = pd.read_csv('TRN', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "\n",
    "features = ds.columns.drop(['INDEX', 'IND_BOM_1_1', 'IND_BOM_1_2'])\n",
    "X = ds[features]\n",
    "y = ds['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features usign RandomForest\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel = sel.fit(X,y)\n",
    "X = sel.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X+y to Dataframe \n",
    "\n",
    "#  X = pd.DataFrame(data=X)\n",
    "# y = pd.DataFrame(data=y)\n",
    "# ds = pd.concat([X,y], axis=1)\n",
    "\n",
    "# Generating heatmap of correlations\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# corrmat = ds.corr()\n",
    "# top_corr_features = corrmat.index\n",
    "# plt.figure(figsize=(300,300))\n",
    "# #plot heat map\n",
    "# g=sns.heatmap(ds[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestfeatures = SelectKBest(score_func=f_classif, k=50)\n",
    "# X = bestfeatures.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for train, validation and test\n",
    "# Train: 1/2\n",
    "# Validation: 1/4\n",
    "# Test: 1/4\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, stratify=y, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.95, stratify=y_train, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [0, 1, 2, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]\n",
    "sm = BorderlineSMOTE(random_state=123, sampling_strategy='minority')\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for testing models\n",
    "\n",
    "# Accuracy: (TP + TN) / N\n",
    "# Precision: TP / (TP + FP)\n",
    "# Recall: TP / (TP + FN)\n",
    "# F1-Measure: Harmonic average between Precision and Recall\n",
    "\n",
    "def compute_metrics(pred, pred_probs, y, neg_class=0):\n",
    "    cm = confusion_matrix(y_true=y, y_pred=pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "    f_measure = f1_score(y, pred)\n",
    "    \n",
    "    pred_probs = np.array([v[0] if v[0] > v[1] else v[1] for v in pred_probs])\n",
    "    roc_auc = roc_auc_score(y, pred_probs)\n",
    "    pr_auc = average_precision_score(y, pred_probs)\n",
    "    gd = generate_dist(pred_probs, np.array(y), neg_class)\n",
    "    ks = ks_2samp(gd[0], gd[1])[0]\n",
    "    return acc, precision, recall, f_measure, roc_auc, pr_auc, ks, cm\n",
    "\n",
    "def report_performance_metrics(pred, pred_probs, _y, neg_class=0):\n",
    "    acc, prec, rec, f_measure, roc_auc, pr_auc, ks, cm = compute_metrics(pred, pred_probs, _y, neg_class)\n",
    "    skplt.metrics.plot_ks_statistic(_y, pred_probs)\n",
    "    plt.show()\n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', rec)\n",
    "    print('F-Measure:', f_measure)\n",
    "    print('AUROC:', roc_auc)\n",
    "    print('AUPR:', pr_auc)\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "def train_test_k_fold(k, clf, _X, _y, neg_class=0):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "    it = 1\n",
    "    for train_index, test_index in skf.split(_X, _y):\n",
    "        X_batch = _X[train_index]\n",
    "        y_batch = _y[train_index]\n",
    "        X_test_batch = _X[test_index]\n",
    "        y_test_batch = _y[test_index]\n",
    "        clf.fit(X_batch, y_batch)\n",
    "        results = clf.predict(X_test_batch)\n",
    "        results_probs = clf.predict_proba(X_test_batch)\n",
    "        print('K Fold it', it)\n",
    "        report_performance_metrics(results, results_probs, y_test_batch, neg_class)\n",
    "        print('')\n",
    "        it += 1\n",
    "        \n",
    "def test_model(clf, _X, _y):\n",
    "    results = clf.predict(_X)\n",
    "    results_probs = clf.predict_proba(_X)\n",
    "    report_performance_metrics(results, results_probs, _y)\n",
    "    \n",
    "def generate_dist(probas, y, neg_class):\n",
    "    dist_1 = [0] * 100\n",
    "    dist_2 = [0] * 100\n",
    "    for_perc = Counter(y)\n",
    "    for i in range(1,101):\n",
    "        limiar = i/100        \n",
    "        lower = y[np.where(probas <= limiar)]\n",
    "        count = Counter(lower)\n",
    "        dist_1[i-1] = count[neg_class]\n",
    "        dist_2[i-1] = count[1]\n",
    "    return np.array(dist_1)/for_perc[neg_class], np.array(dist_2)/for_perc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_X_train = np.delete(X_train, cat_cols, 1)\n",
    "#kk = np.delete(X_val, cat_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''params = {\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'C': [.0001, .01, 1, 10, 100],\n",
    "    'gamma': [.0001, .001, .01, .1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', verbose=True, max_iter=500)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=params)\n",
    "search = grid.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = search.best_params_\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with k fold \n",
    "\n",
    "params = {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "svm_clf = svm.SVC(**params, decision_function_shape='ovo', \n",
    "              verbose=True, max_iter=200, probability=True)\n",
    "\n",
    "_y_train = np.array([v if v == 1 else -1 for v in y_train])\n",
    "\n",
    "train_test_k_fold(5, svm_clf, X_train, _y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SVM  on validation set\n",
    "\n",
    "_y_val = np.array([v if v == 1 else -1 for v in y_val])\n",
    "test_model(svm_clf, X_val, _y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SVM on test set\n",
    "\n",
    "_y_test = np.array([v if v == 1 else -1 for v in y_test])\n",
    "test_model(svm_clf, X_test, _y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP ensemble (Bagging method) and train it\n",
    "\n",
    "_mlp = MLPClassifier(hidden_layer_sizes= (12, 12), learning_rate_init= 0.005, solver= 'adam',\n",
    "                     alpha=1e-4, verbose=True, activation='relu', batch_size=128, max_iter=20, tol=1e-7)\n",
    "\n",
    "mlp_ensemble = BaggingClassifier(base_estimator=_mlp, n_estimators=5, max_samples=.2, \n",
    "                  bootstrap=False, bootstrap_features=True, n_jobs=8, verbose=True)\n",
    "\n",
    "mlp_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLP ensemble on validation set\n",
    "\n",
    "test_model(mlp_ensemble, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLP Ensemble on test set \n",
    "\n",
    "test_model(mlp_ensemble, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search to find best parameters\n",
    "'''\n",
    "    Best parameters found:\n",
    "        Solver: adam\n",
    "        hidden_layers: (12,12)\n",
    "        learning_rate: 0.005\n",
    "'''\n",
    "\n",
    "\n",
    "'''solvers = ['lbfgs', 'adam',]\n",
    "hidden_layers = [(12,12), (12,12,12), (5,5,5), (5,5)]\n",
    "learning_rates = [.001, .0001, .005]\n",
    "\n",
    "clf = MLPClassifier()\n",
    "grid = GridSearchCV(estimator=clf, param_grid=dict(solver=solvers, hidden_layer_sizes=hidden_layers, learning_rate_init=learning_rates))\n",
    "search = grid.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename best parameters found on grid search\n",
    "\n",
    "params = search.best_params_\n",
    "\n",
    "# params = {\n",
    "#     'solver': 'adam',\n",
    "#     'hidden_layer_sizes': (12,12),\n",
    "#     'learning_rate_init': .005,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train MLP with best parameters found on grid search\n",
    "mlp = MLPClassifier(**params, alpha=1e-4, verbose=True, activation='relu', batch_size=128, max_iter=20, tol=1e-7)\n",
    "\n",
    "# Uncomment below line to run k fold on the MLP\n",
    "train_test_k_fold(5, mlp, X_train, y_train)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Keras MLP\n",
    "\n",
    "'''input_dims = X_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=input_dims[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_val, y_val = shuffle(X_val, y_val)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2, shuffle=True, batch_size=128, validation_data=(X_val, y_val))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLP on validation set\n",
    "test_model(mlp, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLP on test set\n",
    "test_model(mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
